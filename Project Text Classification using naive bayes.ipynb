{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models are requried\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import os,sys\n",
    "import re,string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This are stop_words in common taken from intenet.\n",
    "stop_word=[\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\n",
    "\"by\",\"could\",\"did\",\"do\",\"does\",\"doing\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"has\",\"have\",\"having\",\"he\",\"he'd\",\"he'll\",\"he's\",\"her\",\n",
    "\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"it\",\"it's\",\"its\",\"itself\",\"let's\",\"me\",\n",
    "\"more\",\"most\",\"my\",\"myself\",\"nor\",\"of\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"same\",\"she\",\n",
    "\"she'd\",\"she'll\",\"she's\",\"should\",\"so\",\"some\",\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"there's\",\n",
    "\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"we\",\"we'd\",\n",
    "\"we'll\",\"we're\",\"we've\",\"were\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\"who's\",\"whom\",\"why\",\"why's\",\"with\",\n",
    "\"would\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "#read the documnets form all groups of news\n",
    "for category in os.listdir(\"Dataset/Newsgroup/20_newsgroups\"):\n",
    "    for document in os.listdir(\"Dataset/Newsgroup/20_newsgroups/\"+category):\n",
    "        with open(\"Dataset/Newsgroup/20_newsgroups/\"+category+'/'+document,\"r\") as f:\n",
    "            x.append((document,f.read()))\n",
    "            y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "('51127', \"Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!noc.near.net!news.centerline.com!uunet!olivea!sgigate!sgiblab!adagio.panasonic.com!nntp-server.caltech.edu!keith\\nFrom: keith@cco.caltech.edu (Keith Allan Schneider)\\nNewsgroups: alt.atheism\\nSubject: Re: >>>>>>Pompous ass\\nMessage-ID: <1pi9jkINNqe2@gap.caltech.edu>\\nDate: 2 Apr 93 21:01:40 GMT\\nReferences: <1ou4koINNe67@gap.caltech.edu> <1p72bkINNjt7@gap.caltech.edu> <93089.050046MVS104@psuvm.psu.edu> <1pa6ntINNs5d@gap.caltech.edu> <1993Mar30.205919.26390@blaze.cs.jhu.edu> <1pcnp3INNpom@gap.caltech.edu> <1pdjip$jsi@fido.asd.sgi.com>\\nOrganization: California Institute of Technology, Pasadena\\nLines: 14\\nNNTP-Posting-Host: punisher.caltech.edu\\n\\nlivesey@solntze.wpd.sgi.com (Jon Livesey) writes:\\n\\n>>>How long does it [the motto] have to stay around before it becomes the\\n>>>default?  ...  Where's the cutoff point? \\n>>I don't know where the exact cutoff is, but it is at least after a few\\n>>years, and surely after 40 years.\\n>Why does the notion of default not take into account changes\\n>in population makeup?     \\n\\nSpecifically, which changes are you talking about?  Are you arguing\\nthat the motto is interpreted as offensive by a larger portion of the\\npopulation now than 40 years ago?\\n\\nkeith\\n\")\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(type(x[0]))\n",
    "print(type(x[0][0]))\n",
    "print(type(x[0][1]))\n",
    "print(type(y))\n",
    "print(x[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "from sklearn import model_selection\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary of words with their corresponding frquencey\n",
    "dic={}\n",
    "for i in range(len(x_train)):\n",
    "    #look [1] beacuse [0] is  name of the documnets and [1] is text in documnts\n",
    "    word=x_train[i][1]\n",
    "    #split the text into word\n",
    "    strip = re.split(r'\\W+',word)\n",
    "    #iterate over each word\n",
    "    for w in strip:\n",
    "        #we will no include strop word , alpha numeric, punctuations or irrelevent word\n",
    "        if not(w.isalpha()) or w in stop_word or len(w)<2:\n",
    "            continue\n",
    "        if w in dic:\n",
    "            dic[w]+=1\n",
    "        else:\n",
    "            dic[w]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the dictionary on the basis of frequency of words in descending order\n",
    "sort_d = sorted(dic.items(),key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "features = sort_d\n",
    "ans1=[]\n",
    "ans2=[]\n",
    "for i in range(len(features)):\n",
    "    ans1.append(i)\n",
    "    ans2.append(features[i][1])\n",
    "plt.plot(ans1,ans2)\n",
    "plt.axis([0,8000,1,5000])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide to make top 2500 words with max frequency as our feature\n",
    "ans1 = [features[i][0] for i in range(2500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making x_train dataset\n",
    "# no. of rows is equivalent to rows in x_train and column is equal to lenght of ans\n",
    "\n",
    "x_train_data = np.zeros([len(x_train),len(ans1)],int)\n",
    "for i in range(len(x_train)):\n",
    "    word =x_train[i][1].lower()\n",
    "    word =re.split(r'\\W+',word)\n",
    "    \n",
    "    #iterate over the word\n",
    "    for j in word:\n",
    "        #we add the frequency corresponding to that word only which are ans1\n",
    "        if j in ans1:\n",
    "            x_train_data[i][ans1.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making x_test\n",
    "x_test_data  = np.zeros([len(x_test),len(ans1)],int)\n",
    "for i in range(len(x_test)):\n",
    "    word =x_test[i][1].lower()\n",
    "    word = re.split(r'\\W+',word)\n",
    "    #iterate over the each word\n",
    "    for j in word:\n",
    "        # add the frequency corresponding to that word only which in our ans1\n",
    "        if j in ans1:\n",
    "            x_test_data[i][ans1.index(j)]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  4 ...  0  0  0]\n",
      " [12  0  3 ...  0  0  0]\n",
      " [10  0  2 ...  0  0  0]\n",
      " ...\n",
      " [ 7  0  2 ...  0  0  0]\n",
      " [ 7  0  1 ...  0  0  0]\n",
      " [13  0  4 ...  0  0  0]]\n",
      "----------------------------------------\n",
      "[[ 9  0  5 ...  0  0  0]\n",
      " [ 9  0  4 ...  0  0  0]\n",
      " [ 6  0  1 ...  0  0  0]\n",
      " ...\n",
      " [ 5  0  3 ...  0  0  0]\n",
      " [10  0  2 ...  0  0  0]\n",
      " [ 3  0  3 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "#print the x_train and x_test\n",
    "print(x_train_data)\n",
    "print(\"----------------------------------------\")\n",
    "print(x_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of training data 0.8903113956124559\n",
      "Score of test data 0.858\n",
      "[[199   0   0   0   1   0   0   4   2   0   1   0   1   0   1   0   0   2\n",
      "    0  42]\n",
      " [  0 175  15  12  11   6   6   2   1   0   0   0   2   2   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3 232  13   2   9   2   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   4 210  18   1   2   0   1   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   2  18 225   2   3   0   1   0   0   1   3   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  28  36   8   9 169   1   0   1   0   0   0   1   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   4   1   0 254   6   1   0   0   0   2   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   0   0   2   0   0  10 223   9   0   3   0   4   0   0   0   1   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   5   9 254   1   0   0   0   0   2   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   2   2   4 222  18   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   3   3   4   6 239   0   0   0   0   0   0   0\n",
      "    1   0]\n",
      " [  0   2   3   0   0   1   0   0   2   1   0 248   4   1   0   0   1   0\n",
      "    0   0]\n",
      " [  0   2   0  12   0   0   5   4   1   0   0   1 217   2   2   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   1   2   3   5   1   4   1   1   0   3 207   0   0   0   1\n",
      "    0   0]\n",
      " [  0   2   0   0   1   0   1   0   1   3   0   0   7   5 216   0   1   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 266   0   1\n",
      "    0   0]\n",
      " [  0   0   1   1   0   0   0   0   3   0   1   2   0   0   1   0 225   0\n",
      "   12   4]\n",
      " [  0   1   0   0   0   0   2   0   3   0   0   0   1   0   0   0   7 202\n",
      "   13   3]\n",
      " [  0   0   0   0   0   0   1   0   1   2   0   2   0   0   2   3  31  10\n",
      "  181  20]\n",
      " [ 46   1   0   0   0   0   1   1   0   0   1   0   0   0   2  13  13   1\n",
      "   18 126]]\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.81      0.79      0.80       253\n",
      "           comp.graphics       0.80      0.75      0.77       232\n",
      " comp.os.ms-windows.misc       0.79      0.89      0.84       261\n",
      "comp.sys.ibm.pc.hardware       0.75      0.88      0.81       238\n",
      "   comp.sys.mac.hardware       0.83      0.88      0.85       257\n",
      "          comp.windows.x       0.88      0.66      0.75       256\n",
      "            misc.forsale       0.84      0.94      0.89       270\n",
      "               rec.autos       0.87      0.88      0.88       253\n",
      "         rec.motorcycles       0.87      0.93      0.90       272\n",
      "      rec.sport.baseball       0.94      0.90      0.92       248\n",
      "        rec.sport.hockey       0.91      0.93      0.92       257\n",
      "               sci.crypt       0.98      0.94      0.96       263\n",
      "         sci.electronics       0.88      0.88      0.88       246\n",
      "                 sci.med       0.95      0.90      0.92       231\n",
      "               sci.space       0.95      0.91      0.93       238\n",
      "  soc.religion.christian       0.94      1.00      0.97       267\n",
      "      talk.politics.guns       0.81      0.90      0.85       250\n",
      "   talk.politics.mideast       0.93      0.87      0.90       232\n",
      "      talk.politics.misc       0.80      0.72      0.76       253\n",
      "      talk.religion.misc       0.64      0.57      0.60       223\n",
      "\n",
      "                accuracy                           0.86      5000\n",
      "               macro avg       0.86      0.86      0.85      5000\n",
      "            weighted avg       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report , confusion_matrix,accuracy_score\n",
    "\n",
    "clf=MultinomialNB()\n",
    "clf.fit(x_train_data,y_train)\n",
    "y_pred =clf.predict(x_test_data)\n",
    "print(\"Score of training data\",clf.score(x_train_data,y_train))\n",
    "print(\"Score of test data\",clf.score(x_test_data,y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Own scratch code of Naive bayes for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dictionary for implementaing naive bayes\n",
    "\n",
    "def fit(x_train_data,y_train):\n",
    "    count ={}\n",
    "    total_word=0\n",
    "    y_train = np.array(y_train)\n",
    "    # total no of documents is calculated\n",
    "    count[\"total_doc\"]=len(y_train)\n",
    "    classess = set(y_train)\n",
    "    for i in classess:\n",
    "        temp =0\n",
    "        #selecting x_train corresponding to class present in y_train\n",
    "        x_train_with_i=x_train_data[y_train==i]\n",
    "        #finding lenght of data with category corresponding to i\n",
    "        temp2=x_train_with_i.shape[0]\n",
    "        count[i]={}\n",
    "        #Iterating over ans1\n",
    "        for feature in ans1:\n",
    "            #calculating total word in feature\n",
    "            l=(x_train_with_i[:,ans1.index(feature)]).sum()\n",
    "            count[i][feature]=l\n",
    "            temp+=1\n",
    "        #total word in that class\n",
    "        count[i][\"word_in_class\"]=temp\n",
    "        #lenght of data with y_train beloning to specific classes\n",
    "        count[i][\"lenght\"]=temp2\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x_test,dic,classess):\n",
    "    prob = np.log(dic[classess][\"length\"])-np.log(dic[\"total_doc\"])\n",
    "    feature=list(dic[classess].keys())\n",
    "    # -2 is done becaues there will be \"length\" and \"Word in classess\" preseent in features\n",
    "    for j in range(len(feature)-2):\n",
    "        xj=x_test[j]\n",
    "        #if frequency is 0, we will not consider it\n",
    "        if xj==0:\n",
    "            current_prob=0\n",
    "        else:\n",
    "            #extra addition part is laplace correction\n",
    "            num = dic[classess][feature[j]]+1\n",
    "            den=dic[classess][\"word_in_class\"]+len(dic[classess].keys())-2\n",
    "            current_prob=np.log(num)-np.log(den)\n",
    "        prob+=current_prob\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best classess return from here\n",
    "def predict_for_single(x_test,dic):\n",
    "    first_run =True\n",
    "    classess=dic.keys()\n",
    "    for i in classess:\n",
    "        if i==\"total_doc\":\n",
    "            continue\n",
    "        prob=probability(x_test,dic,i)\n",
    "        if first_run or prob>best_prob:\n",
    "            best_prob=prob\n",
    "            first_run=False\n",
    "            best_class=i\n",
    "    return best_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,dic):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        y_pred.append(predict_for_single(x,dic))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_test,y_pred):\n",
    "    count =0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i]==y_test[i]:\n",
    "            count+=1\n",
    "    return count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = fit(x_train_data,y_train)\n",
    "y_pred = predict(x_test_data,dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on testing data 0.7\n",
      "[[204   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4\n",
      "    7  38]\n",
      " [  1 202   0   1   0   6   0   0   0   0   0   9   0   0   0   0   1   3\n",
      "    9   0]\n",
      " [  0  34 150   3   0  52   0   0   0   0   0  10   0   0   0   0   0   1\n",
      "   11   0]\n",
      " [  0  39   0 169   5   1   0   0   0   0   0  15   1   0   0   0   0   2\n",
      "    6   0]\n",
      " [  0  57   1  20 131   6   0   0   0   0   0  29   1   0   1   0   0   2\n",
      "    9   0]\n",
      " [  0  36   2   0   0 205   0   0   0   0   0   5   0   0   1   0   0   1\n",
      "    6   0]\n",
      " [  0  24   0  13   1   1 136   4   0   0   0  13   2   0   7   0   4  11\n",
      "   52   2]\n",
      " [  1   1   0   0   0   1   3 158   0   1   0   2   4   2   3   0  12  17\n",
      "   48   0]\n",
      " [  9   0   0   0   0   0   2  20  79   0   0   7   0   1   7   0  18  57\n",
      "   70   2]\n",
      " [  0   0   0   0   0   0   0   1   0 191   3   0   0   0   2   0   2  27\n",
      "   21   1]\n",
      " [  0   1   0   0   0   0   0   0   0   6 216   0   1   0   0   0   0  19\n",
      "   14   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0 259   0   0   0   0   0   0\n",
      "    3   0]\n",
      " [  0  14   0   4   0   0   0   0   0   0   0  46 108   1  34   0   1   8\n",
      "   29   1]\n",
      " [  0   6   0   0   0   0   0   0   0   0   0   3   0 157   2   0   0   8\n",
      "   52   3]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   5   0   0 205   0   0   5\n",
      "   20   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 258   0   8\n",
      "    1   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   4   0   0   0   0 120  10\n",
      "  114   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 227\n",
      "    5   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   1   0   4  15\n",
      "  224   7]\n",
      " [ 41   0   0   0   0   0   0   0   0   0   0   2   0   0   0   2   4  14\n",
      "   59 101]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Score on testing data\",score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
